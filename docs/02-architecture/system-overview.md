# System Architecture Overview

**Last Updated**: November 6, 2025  
**Version**: 3.2.0

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Browser   â”‚  User asks question in natural language
â”‚ (localhost:  â”‚  â†“
â”‚    3000)     â”‚  "How many employees are there?"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST /query
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI    â”‚  Receives question + database context
â”‚ (localhost:  â”‚  â†“
â”‚    8000)     â”‚  Sends to Groq AI (primary) for SQL generation
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ AI Request (with caching)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Groq AI     â”‚  Generates SQL query (llama-3.3-70b-versatile)
â”‚  (Cloud)     â”‚  â†“ (Schema cached, only question sent on 2+ requests)
â”‚              â”‚  "SELECT COUNT(*) FROM employees"
â”‚  CACHE: 98%  â”‚  â†“ (Falls back to Gemini on error)
â”‚  token save  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ SQL Response
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQLite DB   â”‚  Executes query
â”‚  (Local)     â”‚  â†“
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  Returns results
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚  Displays natural language answer
â”‚   (React)    â”‚  + collapsible SQL and data tables
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack

### Frontend
- **Framework**: Next.js 16.0.1 (App Router, Turbopack)
- **UI Library**: React 19 with TypeScript 5
- **Styling**: Tailwind CSS 4
- **Components**: shadcn/ui (13+ components)
- **Animations**: Framer Motion
- **State Management**: Zustand
- **Theme**: next-themes (dark/light mode)
- **Fonts**: Geist Sans & Geist Mono

### Backend
- **Framework**: FastAPI (Python 3.11+)
- **Database**: SQLite 3
- **AI Service**: 
  - **Primary**: Groq (`llama-3.3-70b-versatile`) - 100K tokens/day per organization
    - **Prompt Caching**: 40-50% faster, 98% token reduction (51x capacity increase)
  - **Fallback**: Google Gemini 2.0 Flash (`gemini-2.0-flash-exp`) - 550 req/day with 11 keys
  - **Failover**: Automatic Groqâ†’Gemini on any error
- **ORM**: Direct SQL (no ORM for simplicity)
- **Validation**: Pydantic v2

### Infrastructure
- **Ports**: 3000 (frontend), 8000 (backend)
- **Process Manager**: Make commands
- **Logging**: Python logging module
- **Configuration**: .env file (python-dotenv)
- **Databases**: 3 SQLite databases (electronics_company.db, airline_company.db, edtech_company.db)

---

## Data Flow
### Sidebar Quick Query Shortcuts (v3.0.0)

The sidebar provides grouped quick query buttons (Easy/Medium/Hard) with icons and color badges. Clicking a button dispatches a custom event to the AskBar, which runs the query and displays results. This enables one-click access to common business questions.

**UI Flow Diagram:**

```
Sidebar â†’ Quick Query Button â†’ AskBar (dispatch event) â†’ Backend â†’ Groq/Gemini AI â†’ SQL â†’ SQLite â†’ Results â†’ AnswerPanel
```

### Query Execution Flow (Modern /ask Endpoint)

```
1. USER INPUT
   â”œâ”€ User types: "How many employees?"
   â””â”€ Click "Ask" or press Enter

2. FRONTEND PROCESSING
   â”œâ”€ Validate input (non-empty)
   â”œâ”€ Get current company from Zustand store
   â”œâ”€ POST to /ask with { question, company_id, section_ids }
   â””â”€ Show loading state with animation

3. BACKEND PROCESSING - SQL GENERATION (WITH CACHING ğŸš€)
   â”œâ”€ Receive request
   â”œâ”€ Validate database ID
   â”œâ”€ Load database schema
   â”œâ”€ Send to AI (UnifiedLLMClient):
   â”‚  â”œâ”€ Try Groq AI first (llama-3.3-70b-versatile, 100K tokens/day)
   â”‚  â”œâ”€ **Prompt Caching**: Schema as system message (static, cached)
   â”‚  â”‚  â””â”€ First request: ~2500 tokens (caches schema for ~hours)
   â”‚  â”‚  â””â”€ Subsequent: ~50 tokens (just question, 98% reduction)
   â”‚  â”œâ”€ On ANY Groq error â†’ Fallback to Gemini (11 keys, 550 req/day)
   â”‚  â”œâ”€ System prompt (schema + instructions) â†’ CACHED by Groq
   â”‚  â””â”€ User question â†’ Fresh each time
   â”œâ”€ Receive SQL from AI (tracks which provider succeeded)
   â”œâ”€ Clean & validate SQL
   â””â”€ Track generation time (genMs: ~0.35s cached, ~0.66s cold)

4. AI PROCESSING - SQL GENERATION (Groq with Caching)
   â”œâ”€ Analyze schema (from cache if available)
   â”œâ”€ Understand question
   â”œâ”€ Generate SQL query
   â”œâ”€ Automatic retry on rate limits (429)
   â”œâ”€ Cache hit: 40-50% faster (0.35s vs 0.66s)
   â””â”€ Return SQL string

5. DATABASE EXECUTION
   â”œâ”€ Parse SQL
   â”œâ”€ Server-side guardrails (DatabaseManager):
   â”‚  â”œâ”€ Check if query is SELECT (vs PRAGMA, EXPLAIN, etc.)
   â”‚  â”œâ”€ If SELECT without LIMIT â†’ append LIMIT 100 (default)
   â”‚  â”œâ”€ If SELECT with LIMIT â†’ cap to MAX_QUERY_RESULTS (1000)
   â”‚  â””â”€ Non-SELECT queries bypass LIMIT enforcement
   â”œâ”€ Execute query against SQLite
   â”œâ”€ Fetch results (columns + rows)
   â”œâ”€ Track execution time (execMs)
   â””â”€ Return rows + metadata

6. BACKEND PROCESSING - RESULT ANALYSIS âœ¨ ENHANCED
   â”œâ”€ Result Summarization (summarizer.py):
   â”‚  â”œâ”€ Compute numeric aggregates (sum, mean, min, max)
   â”‚  â”œâ”€ Identify categorical columns (low cardinality)
   â”‚  â”œâ”€ Detect time columns for trends
   â”‚  â”œâ”€ Intelligent sampling (head + tail for large datasets)
   â”‚  â”œâ”€ Send to AI (UnifiedLLMClient):
   â”‚  â”‚  â”œâ”€ Try Groq AI first (llama-3.3-70b-versatile)
   â”‚  â”‚  â”œâ”€ On error â†’ Gemini fallback (11 keys)
   â”‚  â”‚  â”œâ”€ Business analyst prompt
   â”‚  â”‚  â””â”€ Automatic retry on rate limits
   â”‚  â””â”€ Receive natural language summary (tracks provider used)
   â”‚
   â”œâ”€ Chart Detection (chart_detector.py + ai_chart_selector.py): ğŸ¨ NEW
   â”‚  â”œâ”€ AI-powered selection (primary):
   â”‚  â”‚  â”œâ”€ Analyze data summary (types, cardinality, sample values)
   â”‚  â”‚  â”œâ”€ Consider question context
   â”‚  â”‚  â”œâ”€ Decide: Should we visualize? (yes/no)
   â”‚  â”‚  â”œâ”€ If yes: Select best chart type (bar/pie/line/histogram)
   â”‚  â”‚  â”œâ”€ Generate chart config (x/y columns, data, title)
   â”‚  â”‚  â””â”€ AI reasoning logged for debugging
   â”‚  â”‚
   â”‚  â””â”€ Heuristic fallback (if AI fails):
   â”‚     â”œâ”€ Time series detection â†’ Line charts
   â”‚     â”œâ”€ Categorical aggregation â†’ Bar/Pie charts
   â”‚     â”œâ”€ Numeric distribution â†’ Histograms
   â”‚     â””â”€ Return chart config or null
   â”‚
   â””â”€ Trend Detection (trend_detector.py): ğŸ“Š NEW
      â”œâ”€ Column analysis (temporal, numeric, categorical)
      â”œâ”€ Time series trend detection:
      â”‚  â”œâ”€ Monotonic growth/decline patterns
      â”‚  â”œâ”€ Growth rate calculation
      â”‚  â””â”€ Confidence scoring (0.0-1.0)
      â”œâ”€ Categorical outlier detection:
      â”‚  â”œâ”€ Z-score calculation (|z| > 2.0)
      â”‚  â”œâ”€ High/low outlier identification
      â”‚  â””â”€ Statistical significance
      â”œâ”€ Numeric distribution analysis:
      â”‚  â”œâ”€ Quartile calculation (Q1, median, Q3)
      â”‚  â”œâ”€ Range and spread insights
      â”‚  â””â”€ Concentration patterns
      â””â”€ Return insights array with severity levels

7. AI PROCESSING - ANALYSIS (Groq/Gemini)
   â”œâ”€ SQL Generation: Groq (primary) â†’ Gemini (fallback)
   â”œâ”€ Result Summarization: Groq (primary) â†’ Gemini (fallback)
   â”œâ”€ Chart Selection: Groq (primary) â†’ Gemini (fallback) â†’ Heuristics
   â””â”€ Performance: <50ms (charts/trends), 800-2000ms (SQL/summary)

8. RESPONSE FORMATTING
   â”œâ”€ answer_text: Natural language summary (paragraph + bullets)
   â”œâ”€ sql: Generated SQL query
   â”œâ”€ columns: Column names
   â”œâ”€ rows: Result data
   â”œâ”€ timings: { genMs, execMs }
   â””â”€ meta: { row_count }

9. FRONTEND RENDERING
   â”œâ”€ Display natural language answer in HERO CARD (primary)
   â”œâ”€ SQL in collapsible accordion
   â”œâ”€ Data table in collapsible accordion
   â””â”€ Timings badges (generation + execution)
```

### Error Handling & Resilience

**API Key Rotation** (Both SQL Generation & Summarization):
- 11 Google Gemini API keys configured
- Automatic rotation on rate limit (429) errors
- Total capacity: 550 requests/day (50/day Ã— 11 keys)
- Detailed logging of rotation events

**Retry Logic**:
- SQL Generation: Up to 3 retries per key with exponential backoff
- Summarization: Up to 3 retries per key with exponential backoff
- Rate limits trigger immediate key rotation
- Other errors trigger retry with backoff (1.5s, 3s, 4.5s)

**Graceful Degradation**:
- If SQL generation fails: Return error to user
- If summarization fails: Return enhanced fallback message with data preview
- Users always receive valid SQL + complete results
- Fallback messages are informative, not generic

---
   â”œâ”€ Data table in collapsible accordion
   â””â”€ Animate entrance with Framer Motion
```

---

## Component Architecture

### Frontend Structure

```
frontend/src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ layout.tsx          â† Root layout (theme provider)
â”‚   â”œâ”€â”€ page.tsx            â† Home page (ask bar + results)
â”‚   â””â”€â”€ globals.css         â† Global styles + theme variables
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”œâ”€â”€ navbar.tsx      â† Top navigation
â”‚   â”‚   â”œâ”€â”€ sidebar.tsx     â† Company/section selector
â”‚   â”‚   â””â”€â”€ app-shell.tsx   â† Layout wrapper
â”‚   â”œâ”€â”€ query/
â”‚   â”‚   â””â”€â”€ ask-bar.tsx     â† Question input + examples
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â””â”€â”€ answer-panel.tsx â† NL answer + accordions
â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â””â”€â”€ settings-dialog.tsx â† Preferences dialog
â”‚   â””â”€â”€ ui/                 â† shadcn components
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ api.ts              â† API client functions
â”‚   â”œâ”€â”€ scope.ts            â† Zustand store (company/sections)
â”‚   â”œâ”€â”€ settings.ts         â† User preferences (localStorage)
â”‚   â””â”€â”€ utils.ts            â† Utilities (cn helper)
â””â”€â”€ data/
    â””â”€â”€ companies.ts        â† Company metadata + examples
```

### Backend Structure

```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ database.py          â† DatabaseManager class (215 lines)
â”‚   â”œâ”€â”€ api_key_manager.py   â† API key rotation & failover (200 lines) âœ¨ NEW
â”‚   â”œâ”€â”€ gemini_client.py     â† Gemini AI client wrapper (140 lines) âœ¨ NEW
â”‚   â”œâ”€â”€ sql_generator.py     â† SQL generation & prompts (220 lines) âœ¨ NEW
â”‚   â”œâ”€â”€ query_engine.py      â† Orchestrator (250 lines) âœ¨ REFACTORED
â”‚   â””â”€â”€ summarizer.py        â† Result summarization (153 lines)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ generators.py        â† Electronics data generation (411 lines)
â”‚   â”œâ”€â”€ airline_generators.py â† Airline data generation (684 lines)
â”‚   â”œâ”€â”€ converters.py        â† Excel â†’ SQLite conversion (160 lines)
â”‚   â”œâ”€â”€ schema.py            â† Schema generation (278 lines)
â”‚   â”œâ”€â”€ electronics/         â† (Planned: modular generators)
â”‚   â””â”€â”€ airline/             â† (Planned: modular generators)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py            â† Configuration loading (121 lines)
â”‚   â”œâ”€â”€ logger.py            â† Logging setup (52 lines)
â”‚   â”œâ”€â”€ llm.py               â† Gemini client wrapper (84 lines)
â”‚   â””â”€â”€ exceptions.py        â† Custom exceptions (38 lines)
â””â”€â”€ cli/
    â””â”€â”€ query_cli.py         â† CLI interface (194 lines)

api/
â”œâ”€â”€ main.py                  â† FastAPI app initialization (44 lines) âœ¨ REFACTORED
â”œâ”€â”€ models.py                â† Pydantic request/response models (72 lines) âœ¨ NEW
â””â”€â”€ routes.py                â† Route handlers (336 lines) âœ¨ NEW
```

**Recent Changes** (October 31, 2025):

**ğŸ”§ Core Module Refactoring** (Major improvement):
- âœ… **QueryEngine Refactored**: Split monolithic `query_engine.py` (614 lines) into 4 modular components
  - `api_key_manager.py`: API key rotation & failover logic (200 lines)
  - `gemini_client.py`: Gemini AI client management (140 lines)
  - `sql_generator.py`: SQL generation & prompt engineering (220 lines)
  - `query_engine.py`: Orchestrator following SOLID principles (250 lines, -59%)
- âœ¨ **Benefits**: 
  - Single Responsibility Principle applied
  - Easier testing (mock individual components)
  - Better maintainability (smaller, focused modules)
  - Reusability (APIKeyManager can be used elsewhere)
  - Zero breaking changes (100% backward compatible)

**ğŸŒ API Module Refactoring**:
- âœ… **API Refactored**: Split monolithic `api/main.py` (498 lines) into 3 focused modules
  - `main.py`: FastAPI app + middleware (44 lines)
  - `models.py`: Pydantic models (72 lines)
  - `routes.py`: Route handlers (336 lines)
- âœ¨ **Benefits**: Better separation of concerns, improved maintainability, enhanced testability

---

## Modular Architecture (QueryEngine)

### Before Refactoring
The original `query_engine.py` was a monolithic 614-line file with mixed responsibilities:
- API key rotation logic
- Gemini AI client initialization
- SQL generation and prompt engineering
- Query execution and result formatting

### After Refactoring
Split into 4 focused modules following **Single Responsibility Principle**:

#### 1. **APIKeyManager** (`api_key_manager.py`)
```python
class APIKeyManager:
    """Manages API key rotation for Google Gemini"""
    
    # Singleton pattern with class-level state
    _all_api_keys: List[str] = []
    _current_key_index: int = 0
    _failed_keys: Set[str] = set()
```

**Responsibilities**:
- Load all 11 API keys from `.env` (including commented ones)
- Automatic rotation on rate limit (429) errors
- Track failed keys to avoid retry loops
- Detect rate limit errors via `is_rate_limit_error()`

**Key Methods**:
- `get_current_key()` - Returns active API key
- `rotate_key()` - Switches to next available key
- `reset_failed_keys()` - Reset after quota refresh

#### 2. **GeminiClient** (`gemini_client.py`)
```python
class GeminiClient:
    """Wrapper for Google Gemini AI client"""
    
    def __init__(self, api_key_manager: APIKeyManager):
        self.api_key_manager = api_key_manager
        self.model: GenerativeModel
```

**Responsibilities**:
- Initialize connection to Google Gemini API
- Auto-detect best available model (prefers `gemini-2.0-flash-exp`)
- Reinitialize after API key rotation

**Key Methods**:
- `get_model()` - Returns configured GenerativeModel
- `reinitialize()` - Reconnect with new API key
- `_get_best_model()` - Auto-detect available models

#### 3. **SQLGenerator** (`sql_generator.py`)
```python
class SQLGenerator:
    """Natural language to SQL query generator"""
    
    def __init__(self, schema_text: str, gemini_client: GeminiClient,
                 api_key_manager: APIKeyManager):
        self.schema_text = schema_text
        self.gemini_client = gemini_client
        self.api_key_manager = api_key_manager
```

**Responsibilities**:
- Generate SQL from natural language questions
- Build optimized prompts with schema context
- Clean and validate generated SQL
- Retry logic with automatic key rotation

**Key Methods**:
- `generate(question)` - Main entry point for SQL generation
- `_create_prompt(question)` - Build context-aware prompts
- `_clean_sql(sql)` - Remove markdown, normalize whitespace

#### 4. **QueryEngine** (`query_engine.py`) - Orchestrator
```python
class QueryEngine:
    """Natural language to SQL query engine - Orchestrator"""
    
    def __init__(self, db_manager=None, db_path=None):
        self.api_key_manager = APIKeyManager()
        self.gemini_client = GeminiClient(self.api_key_manager)
        self.sql_generator = SQLGenerator(...)
        self.db_manager = db_manager or DatabaseManager()
```

**Responsibilities**:
- Coordinate all components (delegation pattern)
- Provide unified public API
- Maintain backward compatibility

**Public API** (unchanged):
- `ask(question)` - Main entry point
- `generate_sql(question)` - Generate SQL only
- `execute_query(sql)` - Execute SQL only
- `get_schema_info()` - Get database schema
- `get_available_tables()` - List tables
- `validate_query(sql)` - Validate without executing

### Benefits of Refactoring

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Main file size | 614 lines | 250 lines | **-59%** |
| Longest method | ~90 lines | ~40 lines | **-56%** |
| Cyclomatic complexity | ~25 | ~8 | **-68%** |
| Test structure | 77 tests | 77 tests | **0 regressions** |

**Advantages**:
- âœ… **Testability**: Mock `APIKeyManager`, `GeminiClient` independently
- âœ… **Maintainability**: Find/modify specific logic faster
- âœ… **Reusability**: `APIKeyManager` can be used by other services
- âœ… **Readability**: 250 lines vs 614 lines in main orchestrator
- âœ… **Backward Compatible**: Zero breaking changes to public API

---

## Key Design Decisions

### 1. Answer-First UX
**Decision**: Display natural language answer prominently, hide SQL/data in accordions  
**Rationale**: End users care about answers, not implementation details  
**Trade-off**: Power users need one click to see SQL

### 2. Multi-Database via Zustand
**Decision**: Client-side state management for company/section selection  
**Rationale**: Fast switching without page reloads, persistent in localStorage  
**Trade-off**: State not server-managed (requires client JS)

### 3. SQLite over Postgres
**Decision**: Use SQLite for local databases  
**Rationale**: Zero configuration, portable, perfect for demo/development  
**Trade-off**: Single-writer limitation (acceptable for read-heavy queries)

### 4. Direct SQL (No ORM)
**Decision**: Execute raw SQL queries from AI  
**Rationale**: ORMs add complexity, AI generates SQL anyway  
**Trade-off**: Manual SQL sanitization required

### 5. API Key Rotation
**Decision**: Rotate through 7 Google API keys on 429 errors  
**Rationale**: Free tier limit is 10 req/min per key â†’ 70 req/min total  
**Trade-off**: Requires managing multiple keys

### 6. Framer Motion Animations
**Decision**: Add entrance animations to answer panel  
**Rationale**: Professional feel, visual feedback on state changes  
**Trade-off**: Slight performance overhead (acceptable)

### 7. Settings in localStorage
**Decision**: Persist user preferences in browser localStorage  
**Rationale**: No backend user management needed  
**Trade-off**: Not synced across devices

---

## Data Model

### Company Structure

```typescript
interface Company {
  id: 'electronics' | 'airline';
  name: string;
  description: string;
  icon: string;
  database: string;  // Path to .db file
  sections: Section[];
  examples: string[];
}

interface Section {
  id: string;
  name: string;
  description: string;
  tables: string[];
}
```

### Query Request/Response

```typescript
// Request
interface QueryRequest {
  question: string;
  database: 'electronics' | 'airline';
}

// Response
interface QueryResponse {
  success: boolean;
  sql: string;
  columns: string[];
  rows: any[][];
  row_count: number;
  execution_time: number;
  error?: string;
}
```

---

## Intelligent Business Analyst Architecture ğŸ§  NEW v3.2.0

### Overview

The intelligent analyst handles **vague business problems** that require exploratory analysis rather than single SQL queries. It transforms questions like "My revenue is low" into comprehensive business insights.

**Detection**: 27 keywords trigger analytical mode:
- Analysis-focused: `insight`, `insights`, `analyze`, `analysis`, `recommend`, `improve`, `why`
- Problem-focused: `problem`, `issue`, `challenge`, `solution`, `grow`, `decline`
- Vague problems: "My X is low/high/poor/declining..."

### 5-Stage Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: PROBLEM INTERPRETATION                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: "My revenue is low"                                      â”‚
â”‚ AI Analysis:                                                    â”‚
â”‚  â€¢ Identify focus areas (revenue, customers, products)          â”‚
â”‚  â€¢ Generate hypotheses (small customer base, pricing, etc.)     â”‚
â”‚  â€¢ Define success metrics                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: AI-DRIVEN QUERY PLANNING (WITH SCHEMA AWARENESS) âœ¨    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Problem + DATABASE SCHEMA (embedded in prompt)           â”‚
â”‚ AI Generates: 3-5 exploratory SQL queries                       â”‚
â”‚  âœ… CRITICAL: Schema sent in BOTH system + user messages        â”‚
â”‚  âœ… Prevents hallucinated table names                           â”‚
â”‚                                                                 â”‚
â”‚ Example queries:                                                â”‚
â”‚  1. "Sales Overview" â†’ COUNT orders, SUM revenue, AVG value     â”‚
â”‚  2. "Customer Overview" â†’ COUNT customers, retention metrics    â”‚
â”‚  3. "Top Products" â†’ Revenue by product, top 10                 â”‚
â”‚  4. "Revenue Trends" â†’ Monthly revenue over last 12 months      â”‚
â”‚  5. "Customer Segments" â†’ High/medium/low value breakdown       â”‚
â”‚                                                                 â”‚
â”‚ Token Impact: 9,701 tokens (vs 4,295 without schema)           â”‚
â”‚ Trade-off: +126% tokens BUT 100% query success (worth it!)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: QUERY EXECUTION WITH ERROR HANDLING                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each query:                                                 â”‚
â”‚  â€¢ Execute against SQLite                                       â”‚
â”‚  â€¢ Track success/failure                                        â”‚
â”‚  â€¢ Collect results + errors                                     â”‚
â”‚  â€¢ Add status to SQL comments ("âœ“ 5 rows" or "âŒ FAILED")       â”‚
â”‚                                                                 â”‚
â”‚ Meta tracking:                                                  â”‚
â”‚  â€¢ queries_succeeded: 5                                         â”‚
â”‚  â€¢ queries_failed: 0                                            â”‚
â”‚  â€¢ row_count: 251 (combined)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 4: PATTERN ANALYSIS ACROSS DATA POINTS                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AI Synthesizes:                                                 â”‚
â”‚  â€¢ Cross-query patterns (correlations, contradictions)          â”‚
â”‚  â€¢ Statistical significance                                     â”‚
â”‚  â€¢ Business context interpretation                             â”‚
â”‚  â€¢ Root cause hypotheses                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 5: INSIGHTS + RECOMMENDATIONS GENERATION                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Output:                                                         â”‚
â”‚  â€¢ 4-6 key insights (markdown bullets)                          â”‚
â”‚  â€¢ 5-7 actionable recommendations                               â”‚
â”‚  â€¢ Data points extracted (metrics with categories)              â”‚
â”‚  â€¢ Natural language analysis (executive summary)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Schema Awareness Fix (2025-11-06) ğŸ”§

**Problem**: AI hallucinating table names (e.g., `customer_feedback`, `sales_orders` that don't exist)

**Root Cause**: 
```python
# OLD: Claimed "use previous context" but no context exists
system_message = "You have the database schema from previous conversation."
```

**Solution**: Embed schema explicitly in BOTH prompts
```python
# NEW: Schema in user message for query planning
user_message = f"""
DATABASE SCHEMA (USE ONLY THESE TABLES):
{self.schema_text}  # Full schema embedded (~2500 tokens)

PROBLEM: {problem}

CRITICAL RULES:
- ONLY use table names that exist in schema above
- DO NOT invent or assume table names
"""

# NEW: Also use system_message_with_schema (not system_message_light)
response = llm_client.generate_content(
    user_message,
    system_message=self.system_message_with_schema  # Schema here too
)
```

**Results**:
- **Before**: 0/5 queries succeeded (all hallucinated tables)
- **After**: 5/5 queries succeeded, 251 rows collected
- **Token Cost**: 4,295 â†’ 9,701 tokens (+126%)
- **Decision**: Accuracy prioritized over token savings

### API Response Structure

**Analytical Query Response**:
```json
{
  "query_type": "analytical",
  "answer_text": "### KEY INSIGHTS\n* Insight 1...\n### RECOMMENDATIONS\n1. ...",
  "sql": "-- Query: Sales Overview\n-- Status: âœ“ 1 rows\nSELECT...",
  "columns": ["total_orders", "total_revenue"],
  "rows": [[200, 2910028.14]],
  "analysis": {
    "insights": ["High AOV ($14,550)", "Small customer base (200)"],
    "recommendations": ["Expand acquisition", "Diversify products"],
    "data_points": [{"name": "Total Orders", "value": 200}],
    "queries_used": ["sales_overview", "customer_overview"],
    "success": true
  },
  "meta": {
    "exploratory_queries": 3,
    "queries_succeeded": 3,
    "queries_failed": 0,
    "row_count": 12
  }
}
```

### Fallback UX Enhancements (2025-11-06) ğŸ’¡

**Data Tab Empty State**:
- Contextual message: "Analysis completed without retrieving raw data"
- Explanation: Why analytical queries might not show tables
- Helpful guidance: Focus on insights tab

**SQL Tab Status Indicators**:
```sql
-- Query: Sales Overview
-- Status: âœ“ 5 rows
SELECT COUNT(*) as total_orders...

-- Query: Customer Feedback
-- Status: âŒ FAILED (no such table: customer_feedback)
SELECT * FROM customer_feedback...
```

**Answer Panel Badge**:
- Success: "5/5 queries OK" (green badge)
- Partial: "3/5 queries OK" (yellow badge)
- Shows query success rate at a glance

### Performance Characteristics

- **Total Time**: ~5-6 seconds end-to-end
  - Stage 1 (interpretation): ~1.2s
  - Stage 2 (query planning): ~1.9s (with schema embedding)
  - Stage 3 (execution): ~0.05s per query (0.25s total for 5)
  - Stage 4-5 (analysis): ~1.7s
  
- **Token Usage**: 9,701 per analytical query
  - Schema embedding: ~5,000 tokens (2Ã— for system + user)
  - Problem description: ~500 tokens
  - AI responses: ~4,000 tokens
  - Trade-off: Accuracy (100% success) > token savings

- **Capacity**: With Groq 100K tokens/day
  - ~10 analytical queries/day (vs 39 data queries/day)
  - Each analytical query = ~10 data queries in complexity

### Code Organization

```
src/core/analyst.py (641 lines)
â”œâ”€â”€ BusinessAnalyst class
â”œâ”€â”€ _interpret_problem()        # Stage 1
â”œâ”€â”€ _plan_data_gathering()      # Stage 2 (with schema embedding)
â”œâ”€â”€ _execute_queries()          # Stage 3
â”œâ”€â”€ _analyze_patterns()         # Stage 4
â””â”€â”€ _generate_insights()        # Stage 5

api/routes.py (705 lines)
â”œâ”€â”€ /ask endpoint
â”œâ”€â”€ Analytical query detection (27 keywords)
â”œâ”€â”€ Extract query_data from analyst results
â”œâ”€â”€ Combine SQLs with status comments
â””â”€â”€ Return analysis + SQL + data

frontend/src/components/results/
â”œâ”€â”€ answer-panel.tsx            # Contextual empty states
â”œâ”€â”€ business-analysis-panel.tsx # Insights rendering
â””â”€â”€ insights-panel.tsx          # Trend visualization
```

### Documentation

- **Feature Guide**: [Intelligent Problem-Solving](../03-features/intelligent-problem-solving.md)
- **API Reference**: [/ask Endpoint](../05-api/endpoints.md#post-ask)
- **Maintenance Log**: [Schema Awareness Fix](../07-maintenance/INTELLIGENT_ANALYST_2025-11-06.md)

---

## Security Considerations

### Current Implementation (Development)
- âœ… API keys in .env (not committed)
- âœ… CORS restricted to localhost:3000
- âœ… SQL injection prevented via Gemini AI (generates safe queries)
- âŒ No authentication on API endpoints
- âŒ No rate limiting per user
- âŒ No input sanitization on frontend

### Production Recommendations
- Add API key authentication
- Implement per-user rate limiting
- Add input validation/sanitization
- Use HTTPS for all traffic
- Add SQL query whitelisting
- Log all queries for auditing
- Add CSRF protection
- Restrict CORS to production domain

---

## Performance Characteristics

### Current Metrics
- **Query Response Time**: 1-3 seconds (AI + DB)
  - AI generation: 800ms - 2s
  - SQL execution: 50-200ms
  - Network overhead: 100ms
- **Database Size**: 12 MB total (both databases)
- **Memory Usage**: ~150 MB (backend), ~200 MB (frontend)
- **Concurrent Users**: 10-20 (SQLite limitation)

### Bottlenecks
1. **Google Gemini API latency** (1-2s) - Largest bottleneck
2. **SQLite write locks** - Not an issue for read-only queries
3. **Frontend bundle size** - 1.2 MB (acceptable)

### Optimization Opportunities
- Cache common queries (e.g., "How many employees?")
- Prefetch database schemas
- Use streaming responses for large datasets
- Add pagination for 1000+ row results

---

## Schema Size Limits & Context Window Analysis

### Current Schema Sizes

| Database | Size (Bytes) | Estimated Tokens | % of Context Window |
|----------|--------------|------------------|---------------------|
| Airline (largest) | 8,254 | ~3,301 | 0.33% |
| EdTech | 6,306 | ~2,522 | 0.25% |
| Electronics | 4,235 | ~1,694 | 0.17% |

**Token Estimation Formula**: `tokens â‰ˆ bytes Ã— 0.4` (conservative estimate)

### Maximum Schema Size Capacity

Based on **Gemini 2.0 Flash's 1 million token context window**:

| Limit Type | Size (Bytes) | Size (KB) | % of Context | Multiplier vs Current | Use Case |
|------------|--------------|-----------|--------------|----------------------|----------|
| **Safe Limit** | 250,000 | 244 KB | 10% | 30x | **Recommended for production** |
| **Comfortable Limit** | 500,000 | 488 KB | 20% | 60x | Good balance |
| **Aggressive Limit** | 1,250,000 | 1,220 KB | 50% | 151x | Maximum theoretical |

### Practical Capacity Estimates

**Safe Limit (250 KB)**:
- **50-60 complex tables** with detailed columns, constraints, and relationships
- **150-200 simple tables** with basic structures
- Leaves 90% of context for prompts, queries, and responses
- âœ… **Recommended for production use**

**Comfortable Limit (500 KB)**:
- **100-120 complex tables**
- **300-400 simple tables**
- Leaves 80% of context window available
- âš ï¸ Use with monitoring

**Aggressive Limit (1.2 MB)**:
- Theoretical maximum before impacting performance
- Not recommended - reduces space for query complexity
- Would require careful prompt engineering

### Current System Headroom

Your current largest schema (Airline: 8.2 KB) uses only **0.33%** of the available context window, providing:
- **30x capacity** before reaching safe limits
- **60x capacity** before reaching comfortable limits
- **151x capacity** before reaching theoretical maximum

This means you can comfortably add:
- **45-50 more airline-sized databases** within safe limits
- OR scale a single database to **30x its current complexity**

### Calculation Method

```python
# Token estimation (conservative)
tokens_per_char = 0.4
gemini_context_window = 1_000_000  # tokens

# Example: Airline schema
airline_size = 8254  # bytes
schema_tokens = airline_size * tokens_per_char  # ~3,301 tokens
context_usage = (schema_tokens / gemini_context_window) * 100  # 0.33%

# Safe limit calculation (10% of context)
safe_limit_tokens = gemini_context_window * 0.10  # 100,000 tokens
safe_limit_bytes = safe_limit_tokens / tokens_per_char  # 250,000 bytes
```

### Bottlenecks Beyond Context Window

While the AI context window is generous, watch for these limits:

1. **FastAPI Request Size**: Default ~1 MB (adjustable)
2. **SQLite Metadata Queries**: Slow with 500+ tables
3. **Frontend Rendering**: Large schemas impact UI performance
4. **Memory Usage**: Full schema loaded into RAM

### Recommendations

âœ… **Current Status**: Excellent headroom, no concerns  
âœ… **Growth Path**: Can scale 30x before any optimizations needed  
âš ï¸ **Monitor**: Schema size if planning 100+ table databases  
ğŸ”§ **Optimize When**: Schema exceeds 200 KB (not likely soon)

---

## Scalability Considerations

### Current Limitations
- **Single-threaded SQLite**: Max 10-20 concurrent users
- **API Rate Limits**: 110-165 req/min (11 keys Ã— 10-15 req/min)
- **No horizontal scaling**: Stateful backend

### Scaling Path
1. **Phase 1** (100 users): Add Redis caching, query result caching
2. **Phase 2** (1,000 users): Migrate to PostgreSQL, add read replicas
3. **Phase 3** (10,000 users): Microservices, queue-based query processing
4. **Phase 4** (100,000 users): Kubernetes, auto-scaling, CDN for frontend

---

## Next Steps

- [Data Flow Diagram](data-flow.md) - Detailed sequence diagrams
- [Tech Stack Details](tech-stack.md) - Deep dive into each technology
- [API Key Rotation](api-key-rotation.md) - How 11-key rotation works
- [Design Decisions](design-decisions.md) - Why we chose what we chose

---

**For Implementation Details**: See [Development Setup](../04-development/setup.md)  
**For API Usage**: See [API Reference](../05-api/endpoints.md)
