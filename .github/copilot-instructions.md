# Copilot Instructions - Multi-Database Query System

## üéØ Project Philosophy: Context Engineering

**CRITICAL**: This project uses **Context Engineering** methodology:
- ‚ùå **DO NOT** rely on conversation memory
- ‚úÖ **DO** read documentation files before ANY change
- ‚úÖ **DO** update docs immediately after code changes
- ‚úÖ **DO** use grep/search to find current implementation

**Documentation is the single source of truth, not memory.**

**üó∫Ô∏è BEFORE making ANY change, read**: `docs/00-DOCUMENTATION-MAP.md`  
This map tells you exactly which docs to read and update for any type of change.

---

## üìÅ Project Structure

```
/Volumes/Extreme SSD/code/sql schema/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ copilot-instructions.md     ‚Üê YOU ARE HERE
‚îú‚îÄ‚îÄ docs/                            ‚Üê READ FIRST ALWAYS (NESTED STRUCTURE)
‚îÇ   ‚îú‚îÄ‚îÄ 00-DOCUMENTATION-MAP.md     ‚Üê üó∫Ô∏è META-DOC: Which doc to update when
‚îÇ   ‚îú‚îÄ‚îÄ README.md                   ‚Üê Master overview & quick links
‚îÇ   ‚îú‚îÄ‚îÄ INDEX.md                    ‚Üê Comprehensive navigation
‚îÇ   ‚îú‚îÄ‚îÄ 01-getting-started/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quickstart.md          ‚Üê 5-minute setup guide
‚îÇ   ‚îú‚îÄ‚îÄ 02-architecture/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ system-overview.md     ‚Üê System design & data flow
‚îÇ   ‚îú‚îÄ‚îÄ 03-features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ natural-language.md    ‚Üê AI-powered querying
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ charts-insights.md     ‚Üê Auto-charting & trend detection (NEW v3.1.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyboard-shortcuts.md  ‚Üê Power user shortcuts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.md            ‚Üê User preferences
‚îÇ   ‚îú‚îÄ‚îÄ 04-development/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ setup.md               ‚Üê Development guide
‚îÇ   ‚îú‚îÄ‚îÄ 05-api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ endpoints.md           ‚Üê All API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ 06-database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ electronics_schema.md  ‚Üê Electronics schema (12 tables)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airline_schema.md      ‚Üê Airline schema (16 tables)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edtech_schema.md       ‚Üê EdTech India schema (15 tables, NEW v3.0.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ednite_schema.md       ‚Üê EdNite test results (NEW v3.2.0)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ liqo_schema.md         ‚Üê Liqo Retail schema (5 tables, 37,857 transactions, NEW v3.3.0)
‚îÇ   ‚îú‚îÄ‚îÄ 07-maintenance/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (deployment, troubleshooting, changelog)
‚îÇ   ‚îî‚îÄ‚îÄ archive/                   ‚Üê Legacy docs (never delete)
‚îÇ       ‚îú‚îÄ‚îÄ task-completions/      ‚Üê Historical TASK_X logs
‚îÇ       ‚îî‚îÄ‚îÄ old-structure/         ‚Üê Previous flat structure
‚îú‚îÄ‚îÄ src/                             ‚Üê Core business logic
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py             ‚Üê DatabaseManager class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query_engine.py         ‚Üê QueryEngine orchestrator (250 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_key_manager.py      ‚Üê API key rotation logic (200 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_client.py        ‚Üê Gemini AI client wrapper (140 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sql_generator.py        ‚Üê SQL generation & cleaning (220 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarizer.py           ‚Üê LLM result summarizer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chart_detector.py       ‚Üê Chart pattern detection (380 lines, v3.1.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai_chart_selector.py    ‚Üê AI-powered chart selection (325 lines, v3.1.0)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trend_detector.py       ‚Üê Statistical trend detection (562 lines, v3.1.0)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generators.py           ‚Üê Electronics data generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airline_generators.py   ‚Üê Airline data generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edtech_generators.py    ‚Üê EdTech India data generation (NEW v3.0.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ednite_generators.py   ‚Üê EdNite test data generation (NEW v3.2.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ liqo_generators.py     ‚Üê Liqo Retail data generation (NEW v3.3.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ converters.py           ‚Üê Excel ‚Üí SQL conversion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema.py               ‚Üê Schema generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ electronics/            ‚Üê Electronics data files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airline/                ‚Üê Airline data files
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ edtech/                 ‚Üê EdTech data files (NEW v3.0.0)
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ config.py               ‚Üê Configuration management
‚îÇ       ‚îú‚îÄ‚îÄ logger.py               ‚Üê Logging setup
‚îÇ       ‚îú‚îÄ‚îÄ llm.py                  ‚Üê LLM client with Groq/Gemini + prompt caching (enhanced 2025-11-06)
‚îÇ       ‚îî‚îÄ‚îÄ exceptions.py           ‚Üê Custom exceptions
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                     ‚Üê FastAPI app initialization
‚îÇ   ‚îú‚îÄ‚îÄ models.py                   ‚Üê Pydantic request/response models
‚îÇ   ‚îî‚îÄ‚îÄ routes.py                   ‚Üê API endpoint handlers
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/                        ‚Üê Next.js 16 App Router
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/                   ‚Üê Pages (page.tsx, layout.tsx)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/            ‚Üê React components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout/           ‚Üê Navbar, Sidebar, AppShell
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query/            ‚Üê AskBar component
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ results/          ‚Üê AnswerPanel component
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings/         ‚Üê SettingsDialog component
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/               ‚Üê shadcn/ui components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/                   ‚Üê Utilities
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts            ‚Üê API client
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scope.ts          ‚Üê Zustand store
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.ts       ‚Üê User preferences
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.ts          ‚Üê Helpers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ companies.ts       ‚Üê Company metadata
‚îÇ   ‚îî‚îÄ‚îÄ public/                    ‚Üê Static assets
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                 ‚Üê Pytest fixtures
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_database.py        ‚Üê DB manager tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_query_engine.py    ‚Üê Query engine tests
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_llm_summarizer.py  ‚Üê LLM summarizer tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ       ‚îú‚îÄ‚îÄ test_api.py             ‚Üê API endpoint tests
‚îÇ       ‚îú‚îÄ‚îÄ test_llm_summarizer.py  ‚Üê /ask endpoint tests
‚îÇ       ‚îî‚îÄ‚îÄ test_data_generation.py ‚Üê Data quality tests
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ excel/                      ‚Üê Generated Excel files
‚îÇ   ‚îî‚îÄ‚îÄ database/                   ‚Üê SQLite databases
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_all.py             ‚Üê Generate all data
‚îÇ   ‚îî‚îÄ‚îÄ examples.py                 ‚Üê Example queries
‚îú‚îÄ‚îÄ Makefile                        ‚Üê Build commands
‚îú‚îÄ‚îÄ start_web.sh                    ‚Üê Web server launcher
‚îú‚îÄ‚îÄ requirements.txt                ‚Üê Python dependencies
‚îî‚îÄ‚îÄ .env                            ‚Üê API keys (gitignored)
```

---

## üîç Before Making ANY Change

### Step 1: Locate Documentation (NESTED STRUCTURE)
```bash
# Always start here:
docs/README.md                          # Master overview & quick links
docs/INDEX.md                           # Comprehensive navigation

# Then navigate by topic:
docs/02-architecture/system-overview.md # For system design questions
docs/05-api/endpoints.md                # For API endpoint questions
docs/04-development/setup.md            # For coding standards
docs/06-database/electronics_schema.md  # For schema questions
docs/03-features/natural-language.md    # For AI query feature
docs/03-features/keyboard-shortcuts.md  # For keyboard shortcuts
docs/03-features/settings.md            # For user preferences

# Legacy docs (archived, for reference only):
docs/archive/old-structure/ARCHITECTURE.md    # Old verbose version
docs/archive/task-completions/TASK_X_COMPLETE.md  # Historical logs
```

### Step 2: Read Current Implementation
```python
# Use read_file to see current state
read_file("src/core/query_engine.py", 1, 100)

# Use grep_search to find related code
grep_search(pattern="class QueryEngine", includePattern="src/**/*.py")

# Use semantic_search for concept-based search
semantic_search("how database connection is managed")
```

### Step 3: Verify Context
- Check imports and dependencies
- Review related test files
- Confirm current behavior before changing

---

## üìã Development Workflow

### Adding a Feature
1. **Read**: `docs/02-architecture/system-overview.md` to understand system
2. **Search**: Find related code with `grep_search`
3. **Test First**: Write failing test (TDD)
4. **Implement**: Make minimal changes
5. **Update Docs**: Modify relevant `docs/` files in appropriate folder
6. **Test**: `make test` before committing
7. **Commit**: Follow commit convention below
2. **Search**: Find related code with `grep_search`
3. **Test First**: Write failing test (TDD)
4. **Implement**: Make minimal changes
5. **Update Docs**: Modify relevant `docs/*.md` files
6. **Test**: `make test` before committing
7. **Commit**: Follow commit convention below

### Fixing a Bug
1. **Reproduce**: Write test that fails
2. **Read**: Current implementation
3. **Fix**: Minimal change to pass test
4. **Verify**: Run full test suite
5. **Document**: Update docs if behavior changes

### Refactoring
1. **Test Coverage**: Ensure 80%+ coverage first
2. **Small Steps**: Incremental changes
3. **Test After Each**: Run tests continuously
4. **Update Docs**: Keep documentation current
5. **No Behavior Change**: Refactor = same output

---

## üé® Coding Standards
### Sidebar Quick Query Shortcuts UI

- Use pill-shaped buttons, left-aligned text
- Group by difficulty: Easy (green ‚ú®), Medium (yellow ‚ö°), Hard (red üî•)
- Add color-coded badges and icons for each group
- Micro-interactions: hover scale, shadow, focus-visible ring
- Keyboard accessible, aria-labels for screen readers
- Responsive: touch targets ‚â•44px, vertical stacking on mobile

### Python Style Guide
```python
"""
PEP 8 compliant
Type hints mandatory
Google-style docstrings
Proper error handling
"""

from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)

class DatabaseManager:
    """
    Manages SQLite database connections and queries.
    
    This class handles connection pooling, query execution,
    and schema introspection for multiple databases.
    
    Attributes:
        db_path: Absolute path to SQLite database file
        
    Example:
        >>> db = DatabaseManager("data/database/company.db")
        >>> results = db.execute_query("SELECT * FROM employees LIMIT 5")
        >>> print(results['rows'])
        
    Raises:
        FileNotFoundError: If database file doesn't exist
        sqlite3.Error: If query execution fails
    """
    
    def __init__(self, db_path: str) -> None:
        """Initialize database manager with path validation."""
        if not Path(db_path).exists():
            raise FileNotFoundError(f"Database not found: {db_path}")
        self.db_path = db_path
        logger.info(f"DatabaseManager initialized: {db_path}")
    
    def execute_query(
        self, 
        sql: str, 
        params: Optional[tuple] = None
    ) -> Dict[str, any]:
        """
        Execute SQL query and return results.
        
        Args:
            sql: SQL query string (parameterized)
            params: Query parameters for safe execution
            
        Returns:
            Dict with keys: columns, rows, row_count
            
        Raises:
            sqlite3.Error: If query execution fails
        """
        try:
            # Implementation
            pass
        except sqlite3.Error as e:
            logger.error(f"Query failed: {sql} - {e}")
            raise
```

### Naming Conventions
- **Classes**: `PascalCase` - `QueryEngine`, `DatabaseManager`
- **Functions**: `snake_case` - `execute_query`, `generate_sql`
- **Constants**: `UPPER_SNAKE_CASE` - `API_BASE_URL`, `MAX_RETRIES`
- **Private**: `_leading_underscore` - `_validate_input`, `_clean_sql`
- **Database**: `lowercase_snake_case` - `employees`, `sales_orders`

---

## üß™ Testing Requirements

### Test Coverage Targets
- **Unit Tests**: 90% coverage
- **Integration Tests**: All API endpoints
- **Total Coverage**: Minimum 80%

### Test Structure
```python
import pytest
from pathlib import Path

class TestQueryEngine:
    """Unit tests for QueryEngine class."""
    
    def test_simple_query(self, electronics_db_path):
        """Test basic COUNT query execution."""
        engine = QueryEngine(db_path=electronics_db_path)
        result = engine.query("How many employees?")
        
        assert result['success'] is True
        assert result['row_count'] > 0
        assert 'SELECT' in result['sql'].upper()
```

### Running Tests
```bash
# All tests
make test

# Specific file
pytest tests/unit/test_database.py -v

# With coverage
make test-cov

# Integration only
pytest tests/integration/ -v
```

---

## üåê API Development

### Endpoint Structure
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, List

class QueryRequest(BaseModel):
    """Request model for /query endpoint."""
    question: str
    database: str  # "electronics" or "airline"

@app.post("/query")
async def execute_query(request: QueryRequest) -> Dict:
    """
    Execute natural language query against selected database.
    
    Args:
        request: QueryRequest with question and database ID
        
    Returns:
        {
            "success": bool,
            "sql": str,
            "columns": List[str],
            "rows": List[List],
            "row_count": int,
            "execution_time": float,
            "error": Optional[str]
        }
        
    Raises:
        HTTPException: 400 if invalid database
        HTTPException: 500 if query execution fails
    """
    try:
        # Implementation
        pass
    except Exception as e:
        logger.error(f"Query failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

### API Conventions
- **Base URL**: `http://localhost:8000`
- **CORS**: Enabled for `localhost:3000`
- **Docs**: Auto-generated at `/docs`
- **Health**: `/health` endpoint always available

---

## üíæ Database Conventions

### Schema Design
- **Table names**: `lowercase_snake_case` (e.g., `sales_orders`)
- **Column names**: `lowercase_snake_case` (e.g., `customer_id`)
- **Primary keys**: `id` or `{table}_id` (e.g., `employee_id`)
- **Foreign keys**: Named after referenced table (e.g., `product_id`)
- **Timestamps**: ISO 8601 format

### Example
```sql
CREATE TABLE employees (
    employee_id TEXT PRIMARY KEY,
    first_name TEXT NOT NULL,
    last_name TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL,
    department TEXT,
    hire_date TEXT,
    salary REAL CHECK(salary > 0)
);
```

---

## üîß Make Commands Reference

```bash
# Web Server
make start      # Start frontend (3000) + backend (8000)
make stop       # Stop all servers
make restart    # Restart + clear Python cache

# Development
make install    # Install dependencies
make generate   # Generate all data
make test       # Run test suite
make test-cov   # Run with coverage report

# Cleanup
make clean      # Remove generated files
make clean-all  # Remove files + cache
```

---

## üìù Git Commit Convention

```bash
# Format: <type>(<scope>): <subject>

# Types:
feat      # New feature
fix       # Bug fix
docs      # Documentation only
test      # Adding tests
refactor  # Code restructure (no behavior change)
perf      # Performance improvement
chore     # Maintenance tasks

# Examples:
feat(api): add /stats endpoint for query analytics
fix(query): handle null values in aggregation queries
docs(arch): update system architecture diagram
test(db): add integration tests for connection pooling
refactor(query): extract SQL validation to separate method
```

---

## üö® Error Handling

### Strategy
1. **Catch specific exceptions** (never bare `except:`)
2. **Log with context** (include variables, stack trace)
3. **User-friendly messages** (no technical jargon in UI)
4. **Proper status codes** (400 client, 500 server)
5. **Never expose secrets** (API keys, paths)

### Example
```python
try:
    result = engine.query(question)
except ValueError as e:
    logger.warning(f"Invalid input: {question} - {e}")
    raise HTTPException(status_code=400, detail="Invalid question format")
except GoogleAPIError as e:
    logger.error(f"AI service failed: {e}")
    raise HTTPException(status_code=503, detail="AI service temporarily unavailable")
except Exception as e:
    logger.exception(f"Unexpected error: {e}")
    raise HTTPException(status_code=500, detail="Internal server error")
```

---

## üîê Security Guidelines

- **API Keys**: Store in `.env`, never commit
- **SQL Injection**: Use parameterized queries only
- **Input Validation**: Validate all user inputs
- **CORS**: Restrict origins in production
- **Logging**: Never log sensitive data
- **Rate Limiting**: Respect Google API limits (10/min free tier)

---

## üìö Documentation Update Checklist

Update docs when you:
- ‚úÖ Add/remove API endpoints ‚Üí `docs/05-api/endpoints.md`
- ‚úÖ Change database schema ‚Üí `docs/06-database/electronics_schema.md` or `airline_schema.md` or `edtech_schema.md` or `ednite_schema.md` or `liqo_schema.md`
- ‚úÖ Modify architecture ‚Üí `docs/02-architecture/system-overview.md`
- ‚úÖ Add dependencies ‚Üí `requirements.txt` + `docs/04-development/setup.md`
- ‚úÖ Change build process ‚Üí `Makefile` + `docs/04-development/setup.md`
- ‚úÖ Add feature ‚Üí Create new doc in `docs/03-features/`
- ‚úÖ Fix critical bugs ‚Üí `docs/02-architecture/system-overview.md` (lessons learned)

---

## üéØ Performance Targets

- **Query Response**: < 0.5 seconds (AI + DB, with caching)
- **API Response**: < 500ms (non-AI endpoints)
- **Database Query**: < 100ms
- **Frontend Load**: < 1 second
- **Test Suite**: < 120 seconds
- **Cache Hit Rate**: > 90% (after warmup)

---

## üîÑ Refactoring Triggers

Refactor when:
- **Code duplication** appears 3+ times
- **Function > 50 lines** (extract subfunctions)
- **Class > 300 lines** (split responsibilities)
- **Cyclomatic complexity > 10** (simplify logic)
- **Similar bugs** in 3+ places (architectural issue)

---

## üìä Key Metrics

### Current System Stats
- **Databases**: 5 (electronics, airline, edtech, ednite, liqo)
- **Tables**: 53 total (12 electronics, 16 airline, 15 edtech, 5 ednite, 5 liqo)
- **Data Rows**: 56,500+ (11,265 traditional + 2,540 ednite + 42,695 liqo)
- **Test Coverage**: 95.2% (94/94 tests including domain validation)
- **API Endpoints**: 8 (/health, /databases, /schema, /examples, /ask, /query, /stats, /)
- **Lines of Code**: ~6,800

### External Dependencies

**AI Providers (Dual-stack with automatic failover):**

1. **Groq AI** (Primary - 26x faster, higher quota)
   - Model: llama-3.3-70b-versatile
   - Rate Limit: 100,000 tokens/day per organization (free tier)
   - Speed: ~0.35s per query with caching (86-88% faster than cold start)
   - **Prompt Caching**: 40-50% speed improvement, 98% token reduction
   - Use Case: All SQL generation + result summarization
   - ‚ö†Ô∏è Rate limits are per-organization, not per-key

2. **Google Gemini AI** (Fallback - reliable, proven)
   - Model: gemini-2.0-flash-exp
   - Rate Limit: 50 requests/day per key, 11 keys = 550 req/day total
   - Speed: ~1.5s per query
   - Use Case: Automatic fallback when Groq unavailable/rate-limited

**Failover Strategy:**
- Try Groq first for ALL requests (SQL generation + summarization)
- On ANY Groq error (rate limit, timeout, service down) ‚Üí Gemini
- On Gemini error ‚Üí User-friendly error message
- Transparent to user (answer includes provider info in logs only)

### Prompt Caching System ‚úÖ
**Implemented 2025-11-06** - Reduces token usage by 98% on cached requests

**How It Works:**
- Database schema (~2500 tokens) sent as `system` message (cached)
- User question (~50 tokens) sent as `user` message (fresh)
- Groq automatically caches system message via prefix matching
- Subsequent queries only send the question (50 tokens vs 2500)

**Performance Impact:**
- First query (cold): 0.66s - caches schema
- Cached queries: 0.35s average (47% faster)
- Token savings: 98% reduction per cached request
- Capacity increase: 39 queries/day ‚Üí 2,000 queries/day (51x)

**Implementation:**
```python
# In src/core/sql_generator.py
system_message, user_message = self._create_prompt(question)
sql_text, provider = self.llm_client.generate_content(
    user_message, 
    system_message=system_message  # Cached by Groq
)
```

**Note:** llama-3.3-70b-versatile caches successfully (confirmed by performance tests), but doesn't expose cache metrics in API response yet. Groq is rolling out full caching support to more models over time.

### API Key Rotation System ‚úÖ
The system automatically rotates through multiple API keys when rate limits are hit.

**Both SQL generation AND result summarization** use the same rotation system:

**Configuration** (`src/utils/config.py`):
- `Config.get_all_api_keys()` - Loads all keys from `.env` (including commented ones)
- Detects any line containing GOOGLE_API_KEY=AIza... (including lines commented out with #)

**SQL Generation Rotation** (`src/core/api_key_manager.py`):
- Singleton APIKeyManager class manages key pool
- `get_current_key()` - Returns current active key
- `rotate_key()` - Switches to next available key on rate limit (429)
- `is_rate_limit_error()` - Detects quota/429 errors
- Tracks failed keys to avoid retry loops

**LLM Summarization Rotation** (`src/utils/llm.py`):
- Uses same APIKeyManager singleton
- Automatic retry with key rotation on rate limits
- Exponential backoff for transient errors (1.5s, 3s, 4.5s)
- Detailed logging: "Using API key X/7", "Rate limit hit, rotating..."

**Usage Flow**:
```python
# Both modules use identical pattern:
from src.core.api_key_manager import APIKeyManager

_key_manager = APIKeyManager()

def generate_something():
    for key_attempt in range(_key_manager.get_total_keys()):
        api_key = _key_manager.get_current_key()
        try:
            # ... call Gemini API with api_key
            return result
        except Exception as e:
            if _key_manager.is_rate_limit_error(e):
                _key_manager.rotate_key()  # Try next key
                continue
            raise
```

**How to Add More Keys**:
```bash
# In .env file, add commented lines:
# GOOGLE_API_KEY=AIzaSyAQ_IHtBXN-pw3NRHrEHb27m8kWNfaQ2Uc
# GOOGLE_API_KEY=AIzaSyB5u2kQXrkggkU5KYW1AJMcY6IANj-iz2g
GOOGLE_API_KEY=AIzaSyBEr2uRqe4dMeaPONhT44dpyeu8MZyV4O8  # Active key
```

All keys (commented or not) are automatically detected and used in rotation.

---

## ‚ö° Quick Reference

### Ports
- `3000` - Frontend (HTTP server)
- `8000` - Backend API (FastAPI)

### Paths
- Databases: `data/database/*.db`
- Excel files: `data/excel/*/`
- Logs: `logs/*.log`

### Environment Variables
```bash
# AI Providers (at least one required)
GROQ_API_KEY=your_groq_key_here          # Primary (get from https://console.groq.com/)
GOOGLE_API_KEY=your_gemini_key_here      # Fallback (get from https://makersuite.google.com/)

# Optional
LOG_LEVEL=INFO
```

---

## üéì Remember

1. **Read docs FIRST**, code second
2. **Update docs** with code changes
3. **Test before commit**
4. **Small commits**, clear messages
5. **Context Engineering** = Scalability
6. **Documentation** > Memory
7. **Grep is your friend** - find before you write

---

**Version**: 3.1.0  
**Last Updated**: 2025-11-06  
**Methodology**: Context Engineering  
**Documentation Location**: `docs/` (nested structure)

**Recent Enhancements**:

- **Intelligent Business Analyst (v3.2.0)** (2025-11-06) üß† LATEST:
  - NEW: `src/core/analyst.py` (641 lines) - AI-powered strategic problem solver
  - **Capabilities**: Interprets vague business problems ("My revenue is low") ‚Üí generates custom exploratory SQL ‚Üí synthesizes insights ‚Üí provides recommendations
  - **5-Stage Pipeline**:
    1. Problem interpretation (identify hypotheses, focus areas)
    2. AI-driven query planning (generates 3-5 custom SQL queries based on problem)
    3. Query execution with error handling
    4. Pattern analysis across multiple data points
    5. Business insights + actionable recommendations generation
  - **Schema Awareness Fix** (2025-11-06): Schema now embedded in AI prompts to prevent hallucinated table names
  - **Token Optimization**: Smart schema passing (schema in first call only, ~38% token reduction)
  - **Detection**: 27 keywords detect analytical questions ("improve", "insights", "recommend", "why", etc.)
  - UPDATED: `api/routes.py` - Analytical path returns SQL + data + analysis + insights
  - UPDATED: `api/models.py` - Added BusinessAnalysis model with insights/recommendations
  - UPDATED: `frontend/src/components/results/answer-panel.tsx` - Shows query success/failure badges
  - UPDATED: `frontend/src/components/results/business-analysis-panel.tsx` - Renders insights
  - Performance: ~5-6s end-to-end (3 LLM calls: 1.9s + 1.3s + 1.7s)
  - Tokens: 4,303 per analytical query (down from 6,920, 38% reduction)
  - Examples: "How can I improve sales?" ‚Üí 5 exploratory queries ‚Üí deep analysis with 6 insights + 6 recommendations
  - Documentation: Created `docs/03-features/intelligent-problem-solving.md`

- **Fallback UX Improvements** (2025-11-06) üí°:
  - ENHANCED: Data tab shows helpful message when analytical queries have no data
  - ENHANCED: SQL tab shows query status (‚úì X rows or ‚ùå FAILED) for each exploratory query
  - ENHANCED: Answer panel shows "X/Y queries OK" badge for analytical queries
  - Better error context when queries fail (shows which tables were attempted)

- **Prompt Caching Implementation** (2025-11-06) üöÄ:
  - ENHANCED: `src/core/groq_client.py` - Added system_message parameter for caching
  - ENHANCED: `src/core/sql_generator.py` - Split prompts into system (schema) + user (question)
  - ENHANCED: `src/core/llm_client.py` - Pass system messages through call chain
  - Performance: 40-50% faster queries, 98% token reduction on cached requests
  - Capacity: 39 queries/day ‚Üí 2,000 queries/day (51x increase)
  - Implementation: Schema sent as cached system message, only question sent fresh
  - Documentation: Created `docs/07-maintenance/CACHING_IMPLEMENTATION.md`
  - Note: llama-3.3-70b caches successfully despite not being in official support list

- **AI-Powered Chart Selection** (2025-11-06) üé®:
  - ENHANCED: `src/core/groq_client.py` - Added system_message parameter for caching
  - ENHANCED: `src/core/sql_generator.py` - Split prompts into system (schema) + user (question)
  - ENHANCED: `src/core/llm_client.py` - Pass system messages through call chain
  - Performance: 40-50% faster queries, 98% token reduction on cached requests
  - Capacity: 39 queries/day ‚Üí 2,000 queries/day (51x increase)
  - Implementation: Schema sent as cached system message, only question sent fresh
  - Documentation: Created `docs/07-maintenance/CACHING_IMPLEMENTATION.md`
  - Note: llama-3.3-70b caches successfully despite not being in official support list

- **AI-Powered Chart Selection** (2025-11-06) üé®:
  - UPGRADED: `src/core/chart_detector.py` (395 lines) - Now AI-first with heuristic fallback
  - NEW: `src/core/ai_chart_selector.py` (325 lines) - LLM decides if/what to visualize
  - Two-step AI decision: (1) Should we visualize? (2) If yes, what chart type?
  - Smart "no chart" decisions: Simple counts, single values, text-heavy data ‚Üí table only
  - Context-aware: Considers user's question intent ("compare", "trend", "breakdown")
  - UPDATED: `api/routes.py` - Passes question to chart detector for AI context
  - UPDATED: `api/models.py` - Charts field now optional (may be null if not needed)
  - UPDATED: `frontend/src/components/results/answer-panel.tsx` - Table styling improvements
  - Performance: Single LLM call (~1-2s), falls back to heuristics if AI fails
  - Examples: "How many products?" ‚Üí NO chart, "Compare top vs bottom" ‚Üí BAR chart
  - Documentation: Created `docs/03-features/charts-insights.md` (comprehensive guide)

- **Trend Detection (AI Insights)** (2025-11-06) ‚ú®:
  - NEW: `src/core/trend_detector.py` (562 lines) - Statistical trend detection from query results
  - Detection types: time series (growth/decline), categorical outliers, numeric distributions
  - Unit tests: 24/24 passing (100% coverage for trend detection logic)
  - Integration tests: 7/7 passing (trend metadata in /ask and /query responses)
  - NEW: `frontend/src/components/results/insights-panel.tsx` - Alert-based insights component
  - NEW: `frontend/src/components/ui/alert.tsx` - shadcn/ui alert component
  - UPDATED: `api/routes.py` - Wired trend detection into /ask and /query endpoints
  - UPDATED: `api/models.py` - Added TrendInsight model and trends field in responses
  - UPDATED: `frontend/src/lib/api.ts` - Added TrendInsight TypeScript types
  - UPDATED: `frontend/src/components/results/answer-panel.tsx` - Integrated InsightsPanel
  - Performance: <50ms statistical analysis (pure Python/pandas, no LLM calls)
  - Test coverage: 31/31 tests passing (24 unit + 7 integration)
  - Features: Growth/decline trends, z-score outliers (|z| > 2), quartile distributions, confidence scoring

- **Simple Charts (Auto-charting)** (2025-11-06) ‚ú® (Superseded by AI-powered above):
  - NEW: `src/core/chart_detector.py` (353 lines) - Automatic chart detection from query results
  - Heuristics: time series (line), categorical breakdown (bar/pie), numeric distribution (histogram)
  - Now used as fallback when AI chart selection unavailable
  - Performance: <10ms chart detection, deterministic heuristics
  - Bug fixes: YYYY-MM date format support, pie chart threshold adjusted (‚â§6 ‚Üí ‚â§10 categories)

- **Groq AI Migration** (2025-11-06):
  - Migrated from Gemini-only to Groq (primary) + Gemini (fallback) dual-stack architecture
  - NEW: `src/core/groq_client.py` (190 lines) - Groq AI client with Gemini-compatible interface
  - NEW: `src/core/llm_client.py` (220 lines) - UnifiedLLMClient with automatic Groq‚ÜíGemini failover
  - UPDATED: `src/core/sql_generator.py` - Uses UnifiedLLMClient, tracks provider used
  - UPDATED: `src/utils/llm.py` - Uses UnifiedLLMClient singleton (simplified from 180‚Üí50 lines)
  - UPDATED: `src/core/query_engine.py` - Initializes UnifiedLLMClient
  - UPDATED: `requirements.txt` - Added groq==0.11.0, httpx<0.28 for compatibility
  - Performance: 3-5x faster SQL generation (~0.3s vs ~1.5s), 14,400 req/day vs 550 req/day
  - Test coverage: 68/77 tests passing (88% after migration updates)

- **Major Refactoring** (2025-10-31):
  - Split monolithic `query_engine.py` (614 lines) into 4 modular components
  - `api_key_manager.py` (200 lines) - API key rotation & failover logic
  - `gemini_client.py` (140 lines) - Gemini AI client management
  - `sql_generator.py` (220 lines) - SQL generation & prompt engineering
  - `query_engine.py` (250 lines, -59%) - Orchestrator following SOLID principles

- **LLM Summarization Enhancement** (2025-10-31):
  - Updated `src/utils/llm.py` with APIKeyManager for 11-key rotation
  - Added retry logic with automatic key rotation on rate limits
  - Enhanced fallback messages with data preview when AI unavailable
  - Detailed error logging in `summarizer.py` for debugging

- **API & Frontend Updates**:
  - API refactored into modular structure (main.py, models.py, routes.py)
  - LLM summarizer enhanced with head+tail sampling, executive tone prompts
  - `/ask` endpoint refactored: separate SQL generation & execution timing (genMs, execMs)
  - Frontend types updated: AskRequest/AskResponse match backend
  - AnswerPanel: Natural language answer as hero element

---

## üìñ Next Steps for You

When starting work:
1. Read `docs/README.md` for project overview
2. Check `docs/INDEX.md` for comprehensive navigation
3. Read `docs/02-architecture/system-overview.md` to understand the system
4. Check `docs/05-api/endpoints.md` for API details
5. Review `docs/04-development/setup.md` for dev environment setup
6. Use `grep_search` to find relevant code
7. Make changes incrementally
8. Update documentation in appropriate `docs/0X-category/` folder
9. Run tests
10. Commit with proper message

**Trust the docs, not the memory.** üéØ
